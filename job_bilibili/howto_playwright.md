# B站校招职位爬虫(Playwright版)使用指南

## 1. 项目简介

这是一个基于 Playwright 的 B 站职位信息爬虫，能够自动化爬取 B 站官网发布的社会招聘和校园招聘职位信息，并将数据保存为 JSON 格式的文件。


## 项目地址

+ Github: [https://github.com/andychu46/c1gspider](https://github.com/andychu46/c1gspider)
+ Blog： [https://blog.c1gstudio.com/](https://blog.c1gstudio.com/)


## 2. 技术栈与依赖

- **Python**: 程序开发语言
- **Playwright**: 浏览器自动化工具，用于模拟浏览器行为获取页面数据
- **第三方库**: time, random, json, datetime, argparse, re, os, sys, typing

## 3. 安装与配置

### 3.1 安装依赖

```bash
# 安装 Playwright
pip install playwright

# 安装 Playwright 浏览器驱动
playwright install
```

### 3.2 项目结构

```
├── bilibili/
│   ├── test_playwright.py  # 主程序文件
│   ├── data/               # 数据保存目录
│   └── howto_playwright.md            # 使用指南文档
```

## 4. 运行方式

程序支持通过命令行参数控制爬取行为，主要参数包括招聘类型、爬取间隔、代理设置、起始页和最大爬取页数等。

### 4.1 基本语法

```bash
python test_playwright.py [参数选项]
```

### 4.2 可用参数

| 参数 | 说明 | 示例 |
|------|------|------|
| `--type` | 招聘类型 (social=社会招聘, campus=校园招聘, all=全部) | `--type social` |
| `--sleep` | 页面爬取间隔（秒） | `--sleep 2.5` |
| `--proxy` | 代理服务器地址 | `--proxy http://127.0.0.1:7890` |
| `--start-page` | 起始页码 | `--start-page 3` |
| `--max-page` | 最大抓取页数 (0为不限制) | `--max-page 10` |d


### 4.3 运行示例

#### 爬取校园招聘职位

```bash
python test_playwright.py --type campus --sleep 1.5 --max-page 5
```

#### 使用代理爬取社会招聘职位

```bash
python test_playwright.py --type social --proxy http://127.0.0.1:7890 --start-page 2
```

## 5. 程序运行流程

整个程序的运行流程可以分为以下几个主要阶段：

### 5.1 参数解析与初始化

1. 解析命令行参数，确定爬取配置
2. 初始化爬虫开始时间
3. 根据招聘类型确定爬取的URL

### 5.2 浏览器初始化

程序通过 `init_browser()` 函数初始化 Playwright 和浏览器环境：

1. 根据操作系统类型决定是否使用无头模式（Linux下默认无头，其他系统默认有界面）
2. 启动 Chromium 浏览器，配置浏览器参数（禁用自动化控制检测、禁用扩展等）
3. 创建浏览器上下文，设置随机 User-Agent
4. 创建新的页面对象并设置超时时间

### 5.3 页面访问与数据获取

1. 首次访问职位列表页面（带重试机制）
2. 获取职位类型和工作地点等字典数据
3. 解析页面，获取最大页码数
4. 根据设置的起始页和最大爬取页数，开始循环爬取

### 5.4 职位信息提取

对于每一页的职位信息，程序执行以下步骤：

1. 加载当前页职位列表
2. 获取职位卡片列表
3. 遍历每个职位卡片：
   - 提取列表页上的基本信息（职位标题、地点、类别、工作类型、发布日期）
   - 模拟点击职位标题，打开新窗口查看详情
   - 在详情页提取更详细的职位信息
   - 构建完整的职位数据字典
4. 将当前页数据添加到总数据列表
5. 定期保存数据（每收集50条），避免意外丢失

### 5.5 数据保存

程序使用 `save_job_list_data()` 函数将爬取的数据保存为 JSON 文件：

1. 创建 `data` 目录（如果不存在）
2. 生成包含时间戳的文件名
3. 将职位数据列表保存为 JSON 格式

### 5.6 程序结束处理

1. 关闭页面、浏览器上下文和浏览器
2. 执行垃圾回收
3. 生成并打印爬取报告（包括开始时间、总页数、爬取页数、收集职位总数、是否成功、完成时间等信息）

## 6. 数据结构

爬取的职位数据包含以下字段：

```json
{
  "position_id": "职位ID",
  "position_title": "职位名称",
  "location": "工作地点",
  "category": "职位类别",
  "job_type": "工作类型",
  "post_date": "发布日期",
  "position_url": "职位详情页URL",
  "position_detail": {
    "position_id": "职位ID",
    "position_url": "职位详情页URL",
    "title": "职位名称",
    "location": "工作地点",
    "category": "职位类别",
    "job_type": "工作类型",
    "post_date": "发布日期",
    "position_content": "职位详情内容"
  },
  "crawl_time": "爬取时间"
}
```

## 7. 防反爬策略

程序包含多种防反爬策略：

1. 随机 User-Agent：每次运行随机选择一个浏览器标识
2. 随机爬取间隔：在指定的爬取间隔基础上随机波动
3. 指数退避重试：请求失败时使用指数退避算法进行重试
4. 模拟真人行为：点击操作前加入随机延迟
5. 禁用自动化检测：配置浏览器参数，避免被网站检测为自动化工具

## 8. 常见问题与解决方案

### 8.1 浏览器启动失败

**问题**：程序无法启动浏览器，报初始化错误

**解决方案**：
- 确认 Playwright 已正确安装：`playwright install`
- 检查系统权限，确保有足够权限启动浏览器
- 对于 Linux 系统，可能需要安装额外的依赖库

### 8.2 页面加载超时

**问题**：页面加载超时，无法获取职位信息

**解决方案**：
- 增加 `--sleep` 参数值，延长爬取间隔
- 使用 `--proxy` 参数设置代理，避免IP被限制
- 检查网络连接是否稳定

### 8.3 职位数据为空

**问题**：爬取完成但数据为空

**解决方案**：
- 检查网站结构是否发生变化（可能需要更新选择器）
- 确认爬取的URL是否正确
- 尝试调整起始页和最大爬取页数参数

## 9. 代码优化建议

1. **错误处理增强**：可以增加更细粒度的错误处理，针对不同类型的错误采取不同的重试策略
2. **并发爬取**：考虑引入异步或多线程爬取，提高效率（注意控制并发数，避免触发反爬）
3. **数据去重**：增加数据去重机制，避免重复爬取相同的职位信息
4. **定时任务**：结合定时任务工具，实现定期自动爬取
5. **日志系统**：引入专业的日志系统替代 `print`，方便问题排查和监控

## 10. 注意事项

1. 请遵守网站的 robots.txt 规则和使用条款
2. 合理设置爬取频率，避免对网站服务器造成过大压力
3. 爬虫仅供学习和研究使用，请勿用于非法用途
4. 定期更新代码以适应网站结构的变化

---

通过本指南，您应该能够理解并成功运行 B 站职位爬虫程序。如有任何问题或建议，欢迎提交反馈。